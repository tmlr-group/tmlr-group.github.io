<!DOCTYPE html>
<!-- TypeIt package -->
<script src="https://code.jquery.com/jquery-3.0.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/jquery.typeit/4.4.0/typeit.min.js"></script>

<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="AAAI'24 Tutorial">
  <meta name="keywords" content="Trustworthy Machine Learning, Label Noise, Adversary, Imbalance">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Trustworthy Machine Learning Under Imperfect Data</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./../static/css/bulma.min.css">
  <link rel="stylesheet" href="./../static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./../static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./../static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./../static/css/index.css">
  <link rel="icon" href="./../static/images/TMLR.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./../static/js/fontawesome.all.min.js"></script>
  <script src="./../static/js/bulma-carousel.min.js"></script>
  <script src="./../static/js/bulma-slider.min.js"></script>
  <script src="./../static/js/index.js"></script>

  <!-- Typing Effect JS -->
  <script src="https://code.jquery.com/jquery-3.0.0.min.js"></script>
  <script src="https://cdn.jsdelivr.net/jquery.typeit/4.4.0/typeit.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/typeit/5.10.1/typeit.min.js"></script>
  <!-- / Typing Effect JS -->

  <style>
    .bigdiv {
      font-size: large;
      font-family: "Courier New";
      padding: 2rem;
    }
    p {
      padding: 2rem;
    }

  </style>

</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Trustworthy Machine Learning Under Imperfect Data</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://sunarker.github.io/">Jiangchao Yao</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://fengliu90.github.io/">Feng Liu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://bhanml.github.io/">Bo Han</a><sup>3</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Shanghai Jiao Tong University</span>
            <span class="author-block"><sup>2</sup>The University of Melbourne</span>
            <span class="author-block"><sup>3</sup>Hong Kong Baptist University</span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            ``Knowledge should not be accessible only to those who can pay'' said Robert May, chair of UC's faculty Academic Senate. Similarly, machine learning should not be accessible only to those who can pay. Thus, machine learning should benefit to the whole world, especially for developing countries in Africa and Asia. When dataset sizes grow bigger, it is laborious and expensive to obtain perfect data (e.g., clean, safe, and balanced data), especially for developing countries. As a result, the volume of imperfect data becomes enormous, e.g., web-scale image and speech data with noisy labels, images with specific noise, and long-tail-distributed data. However, standard machine learning assumes that the supervised information is fully correct and intact. Therefore, imperfect data harms the performance of most of the standard learning algorithms, and sometimes even makes existing algorithms break down. In this tutorial, we focus on trustworthy learning when facing three types of imperfect data: noisy data, adversarial data, and long-tailed data.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
            <b>Trustworthy Learning under Noisy Data.</b> There are a brunch of theories and approaches proposed to deal with noisy data. As far as we know, label-noise learning spans over two important ages in machine learning: statistical learning (i.e., shallow learning) and deep learning. In the age of statistical learning, label-noise learning focused on designing noise-tolerant losses or unbiased risk estimators. Nonetheless, in the age of deep learning, label-noise learning has more options to combat with noisy labels, such as designing biased risk estimators or leveraging memorization effects of deep networks. In this tutorial, we summarize the foundations and go through the most recent noisy-supervision-tolerant techniques. By participating the tutorial, the audience will gain a broad knowledge of label-noise learning from the viewpoint of statistical learning theory, deep learning, detailed analysis of typical algorithms and frameworks, and their real-world applications in industry.
            <br>
            <br>
            <b>Trustworthy Learning under Adversarial Data.</b> Existing deep learning techniques have made real-world deployments of machine learning algorithms be possible. However, the existence of adversarial data significantly reduces the safety of models trained using machine learning algorithms. To handle this risk, researchers focus on two aspects: detecting adversarial data before prediction/classification (a.k.a., adversarial data detection) and making the models generalize well on adversarial data (a.k.a., adversarial training). In this tutorial, we summarize the foundations and statistical properties of adversarial data and go through the most recent adversarial data detection and adversarial training techniques, from the viewpoint of statistics and machine learning, and their applications in industry.
            <br>
            <br>
            <b>Trustworthy Learning under Long-tailed Data.</b> Long-tailed learning has been drawn attention in many research areas like information retrieval, computer vision and medical data analysis, with developing a range of methods to deal with this problem. In a nutshell, the taxonomy behind these methods can be summarized as three categories, data augmentation, model personalization and loss design. All these methods explore a constrained trade-off between majorities and minorities to purse the best overall performance. In this tutorial, we will systematically discuss some basics of three different directions and give the specific examples to help the audiences to understand the past, present and future for long-tailed learning.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Prerequisites for Audiences</h2>
        <div class="content has-text-justified">
          <p>
              <b>Duration:</b> 80 minuates
              <br>
              <b>Abstract:</b> Trustworthy learning under noisy data has been a long-standing problem in machine learning and related fields. The first part of this tutorial will introduce the basics and state-of-the-art research of trustworthy learning under noisy data from various aspects, including trustworthy statistical learning, trustworthy representation learning, applications, and theories. At the beginning of the tutorial, I will briefly give an overview of this field and explain the structure of the first tutorial. Then, a fundamental question in trustworthy statistical learning under noisy data is to study the difference between the classifier learned with noisy data and the classifier learned with clean data. A algorithm is classifier-consistent if the classifier learned from the noisy data is consistent to the optimal classifier defined by using clean data. Therefore, we will comprehensively review recent progress in building classifier-consistent algorithms. Specifically, we will dive into the basics of the robust-loss-function-based methods and the transition-matrix-based methods. Lastly, It is challenging to train deep neural networks robustly with noisy data, as the capacity of deep neural networks is so high that they can totally overfit on these noisy labels. Therefore, we will comprehensively review the recent progress of trustworthy representation learning, namely label-noise representation learning. Moreover, we will introduce three representative techniques in label-noise representation learning, such as data perspective “estimating the noise transition matrix”, training perspective “training on selected samples” and regularization perspective “stochastic integrated gradient underweighted ascent”.
              <br>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Part-I: Trustworthy Machine Learning Under Noisy Data</h2>
        <table class="imgtable">
                <tbody>
                    <tr valign="top">
                        <td><img src="./../static/images/bhan.jpg" alt="Bo Han" height="400" width="280"></td>
                        <td align="left">
                            <p>
                                <span style="font-size: 120%"> <b>Bo Han</b> </span>
                                <br>
                                Assistant Professor @ <a href="https://www.comp.hkbu.edu.hk/v1/?page=home" target="_blank">Department of Computer Science</a><br>
                                <a href="https://www.hkbu.edu.hk/en.html" target="_blank">Hong Kong Baptist University</a>
                                <br>
                                <a href="https://www.riken.jp/en/news_pubs/news/2020/20200319_1/index.html" target="_blank">BAIHO</a> Visiting Scientist @ <a href="https://aip.riken.jp/labs/generic_tech/imperfect_inf_learn/" target="_blank">Imperfect Information Learning Team</a><br>
                                <a href="http://www.riken.jp/en/" target="_blank">RIKEN</a>
                                <a href="https://aip.riken.jp/" target="_blank">Center for Advanced Intelligence Project</a>
                                <br>
                                <a href="https://scholar.google.com/citations?user=nTNjqHwAAAAJ&hl=en" target="_blank">[Google Scholar]</a>
                                <a href="https://github.com/bhanML" target="_blank">[Github]</a>
                                <a href="https://github.com/tmlr-group" target="_blank">[Group Website]</a><br>
                                E-mail: bhanml@comp.hkbu.edu.hk & bo.han@a.riken.jp<br>
                            </p>
                        </td>
                    </tr>
                </tbody>
            </table>
        <div class="content has-text-justified">
          <p>
            Although we will introduce the basics of knowledge required, it is better to have some knowledge in linear algebra, probability, machine learning, and artificial intelligence. The emphasis will be on the intuition behind all the formal concepts, theories, and methodologies. The tutorial will be self-contained in a high level. Besides, audiences who are familiar with the basic robustness under noise, adversary and imbalance will find the comprehensive advances of areas.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Part-I: Trustworthy Machine Learning Under Noisy Data</h2>
        <table class="imgtable">
                <tbody>
                    <tr valign="top">
                        <td><img src="./../static/images/bhan.jpg" alt="Bo Han" height="200" width="140"></td>
                        <td align="left">
                            <p>
                                <span style="font-size: 120%"> <b>Bo Han</b> </span>
                            </p>
                            <p>
                                Assistant Professor @ Electronic Engineering
                                <br />
                                Cooperative Medianet Innovation Center
                                <br />
                                Shanghai Jiao Tong University, China
                                <br />
                            </p>
                            <p>
                                Research Scientist
                                <br />
                                Shanghai AI Laboratory, China
                                <br />
                            </p>
                            <p>
                                Email: Sunarker[at]sjtu.edu.cn
                                <br />
                                [<a href="https://scholar.google.com/citations?user=w8oDh9QAAAAJ&hl=zh-CN">Google Scholar</a>] [<a href="https://github.com/Sunarker">Github</a>]
                            </p>
                        </td>
                    </tr>
                </tbody>
            </table>
        <div class="content has-text-justified">
          <p>
            Although we will introduce the basics of knowledge required, it is better to have some knowledge in linear algebra, probability, machine learning, and artificial intelligence. The emphasis will be on the intuition behind all the formal concepts, theories, and methodologies. The tutorial will be self-contained in a high level. Besides, audiences who are familiar with the basic robustness under noise, adversary and imbalance will find the comprehensive advances of areas.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Part-I: Trustworthy Machine Learning Under Noisy Data</h2>
        <table class="imgtable">
                <tbody>
                    <tr valign="top">
                        <td><img src="./../static/images/bhan.jpg" alt="Bo Han" height="200" width="140"></td>
                        <td align="left">
                            <p>
                                <span style="font-size: 120%"> <b>Bo Han</b> </span>
                            </p>
                            <p>
                                Assistant Professor @ Electronic Engineering
                                <br />
                                Cooperative Medianet Innovation Center
                                <br />
                                Shanghai Jiao Tong University, China
                                <br />
                            </p>
                            <p>
                                Research Scientist
                                <br />
                                Shanghai AI Laboratory, China
                                <br />
                            </p>
                            <p>
                                Email: Sunarker[at]sjtu.edu.cn
                                <br />
                                [<a href="https://scholar.google.com/citations?user=w8oDh9QAAAAJ&hl=zh-CN">Google Scholar</a>] [<a href="https://github.com/Sunarker">Github</a>]
                            </p>
                        </td>
                    </tr>
                </tbody>
            </table>
        <div class="content has-text-justified">
          <p>
            Although we will introduce the basics of knowledge required, it is better to have some knowledge in linear algebra, probability, machine learning, and artificial intelligence. The emphasis will be on the intuition behind all the formal concepts, theories, and methodologies. The tutorial will be self-contained in a high level. Besides, audiences who are familiar with the basic robustness under noise, adversary and imbalance will find the comprehensive advances of areas.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<div class="column has-text-centered">
    <div class="publication-links">
      <!-- PDF Link. -->
      <span class="link-block">
        <a href="http://arxiv.org/abs/2311.03191"
           class="external-link button is-normal is-rounded is-dark">
          <span class="icon">
              <i class="fas fa-file-pdf"></i>
          </span>
          <span>Paper</span>
        </a>
      </span>
  </div>
</div>



<!-- Typing Effect Borader -->
<style>

  .outer_bordered {
    /* width: 1000px; */
    /* ;
    height: 500px;
    padding: 20px; */
    display: inline-block;
    border: 2px solid rgb(0, 157, 255);
    border-radius: 8px;
  }

  .Q_bordered {
    /* width: 700px; */
    /* width: 700px;
    height: 100px;
    */
    padding: 0px;
    display: inline-block;
    border: 2px solid rgb(0, 157, 255);
    border-radius: 8px;
  }

  .A_bordered {
    /* width: 800px;
    height: 500px;
    padding: 20px; */
    display: inline-block;
    border: 4px solid rgb(0, 157, 255);
    border-radius: 8px;
  }
</style>
